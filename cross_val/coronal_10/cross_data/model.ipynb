{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<00:00, 716.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83       0.53      0.566      0.547      0.387\n",
      "              negative         32         34      0.468        0.5      0.479      0.366\n",
      "              positive         46         49      0.592      0.633      0.614      0.408\n",
      "Speed: 3.6ms preprocess, 4.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.512      0.706      0.605      0.453\n",
      "              negative         32         34      0.422      0.765      0.559      0.445\n",
      "              positive         46         49      0.601      0.646      0.651      0.461\n",
      "Speed: 4.3ms preprocess, 1.8ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross2\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.563      0.782      0.672      0.488\n",
      "              negative         32         34      0.473      0.912      0.624       0.49\n",
      "              positive         46         49      0.653      0.653      0.719      0.486\n",
      "Speed: 4.0ms preprocess, 1.8ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross3\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.539      0.775       0.64      0.469\n",
      "              negative         32         34      0.487      0.794      0.633      0.491\n",
      "              positive         46         49       0.59      0.755      0.648      0.447\n",
      "Speed: 18.2ms preprocess, 1.8ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross4\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.619      0.703      0.665      0.485\n",
      "              negative         32         34       0.57      0.794      0.631      0.506\n",
      "              positive         46         49      0.667      0.612      0.699      0.463\n",
      "Speed: 2.5ms preprocess, 1.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross5\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.512      0.708      0.572      0.444\n",
      "              negative         32         34      0.464      0.765      0.508      0.422\n",
      "              positive         46         49      0.561      0.651      0.637      0.465\n",
      "Speed: 3.7ms preprocess, 1.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross6\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.536      0.735      0.667      0.501\n",
      "              negative         32         34      0.555      0.735       0.68      0.525\n",
      "              positive         46         49      0.517      0.735      0.655      0.476\n",
      "Speed: 2.7ms preprocess, 1.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross7\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.507      0.715      0.614      0.454\n",
      "              negative         32         34      0.486      0.882      0.607      0.473\n",
      "              positive         46         49      0.528      0.547      0.622      0.435\n",
      "Speed: 2.4ms preprocess, 1.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross8\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83       0.49      0.767      0.595      0.434\n",
      "              negative         32         34      0.468       0.88      0.578      0.432\n",
      "              positive         46         49      0.511      0.653      0.611      0.437\n",
      "Speed: 2.6ms preprocess, 1.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross9\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal_10/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.557      0.741      0.644      0.456\n",
      "              negative         32         34        0.5      0.706      0.651      0.513\n",
      "              positive         46         49      0.615      0.776      0.636      0.399\n",
      "Speed: 3.0ms preprocess, 1.5ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€í•˜ë ¤ëŠ” ëª¨ë¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "model_paths = [\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train2/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train3/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train4/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train5/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train6/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train7/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train8/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train9/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal_10/cross_data/kfold_demo/train10/weights/best.pt\",\n",
    "]\n",
    "\n",
    "experiment_name = 'test'\n",
    "work_name = 'cross'\n",
    "train_dir = os.path.join('runs', experiment_name)\n",
    "\n",
    "# ê¸°ì¡´ ê²°ê³¼ í´ë” ì‚­ì œ\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "\n",
    "# ë©”íŠ¸ë¦­ ê°’ì„ ì €ìž¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "metric_values = dict()\n",
    "\n",
    "# ê° ëª¨ë¸ì— ëŒ€í•´ í‰ê°€ ìˆ˜í–‰\n",
    "for model_path in model_paths:\n",
    "    train_model = YOLO(model_path)\n",
    "    results = train_model.val(name=os.path.join(experiment_name, f'{experiment_name}_{work_name}'), split=\"test\")\n",
    "    \n",
    "    # ê²°ê³¼ ë©”íŠ¸ë¦­ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ìž¥\n",
    "    for metric, metric_val in results.results_dict.items():\n",
    "        if metric not in metric_values:\n",
    "            metric_values[metric] = []\n",
    "        metric_values[metric].append(metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
      "mean              0.536452           0.719724          0.622041   \n",
      "std               0.036754           0.061442          0.042752   \n",
      "min               0.489777           0.566327          0.546533   \n",
      "max               0.618548           0.782413          0.671584   \n",
      "\n",
      "      metrics/mAP50-95(B)   fitness  \n",
      "mean             0.457047  0.473546  \n",
      "std              0.032307  0.033093  \n",
      "min              0.386953  0.402911  \n",
      "max              0.500729  0.517398  \n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°í”„ë ˆìž„ ìƒì„±\n",
    "metric_df = pd.DataFrame.from_dict(metric_values)\n",
    "\n",
    "# ì›í•˜ëŠ” ë©”íŠ¸ë¦­ë“¤ì˜ í†µê³„ëŸ‰ ì¶œë ¥\n",
    "visualize_metric = ['mean', 'std', 'min', 'max']\n",
    "metric_summary = metric_df.describe().loc[visualize_metric]\n",
    "\n",
    "print(metric_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
