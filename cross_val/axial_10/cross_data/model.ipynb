{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.755      0.837      0.859      0.634\n",
      "              negative         75         81      0.755      0.837      0.859      0.634\n",
      "Speed: 2.8ms preprocess, 1.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.803      0.852      0.911      0.669\n",
      "              negative         75         81      0.803      0.852      0.911      0.669\n",
      "Speed: 2.8ms preprocess, 1.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross2\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.911      0.827      0.898      0.662\n",
      "              negative         75         81      0.911      0.827      0.898      0.662\n",
      "Speed: 1.9ms preprocess, 1.4ms inference, 0.0ms loss, 26.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross3\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.818      0.765      0.855      0.641\n",
      "              negative         75         81      0.818      0.765      0.855      0.641\n",
      "Speed: 2.7ms preprocess, 1.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross4\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|â–ˆâ–ˆ        | 1/5 [02:01<08:07, 121.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:21<00:00, 40.40s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.907      0.839      0.898      0.688\n",
      "              negative         75         81      0.907      0.839      0.898      0.688\n",
      "Speed: 125.2ms preprocess, 9.9ms inference, 0.0ms loss, 286.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross5\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.904      0.815      0.903      0.664\n",
      "              negative         75         81      0.904      0.815      0.903      0.664\n",
      "Speed: 3.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross6\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81       0.83      0.846      0.895      0.657\n",
      "              negative         75         81       0.83      0.846      0.895      0.657\n",
      "Speed: 126.6ms preprocess, 4.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross7\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:50<00:00, 46.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.895      0.842      0.879      0.654\n",
      "              negative         75         81      0.895      0.842      0.879      0.654\n",
      "Speed: 2.9ms preprocess, 1.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross8\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.903      0.805      0.905      0.669\n",
      "              negative         75         81      0.903      0.805      0.905      0.669\n",
      "Speed: 2.7ms preprocess, 1.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross9\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/axial_10/yolo_data/labels/test.cache... 75 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         81      0.844       0.84      0.891      0.667\n",
      "              negative         75         81      0.844       0.84      0.891      0.667\n",
      "Speed: 2.6ms preprocess, 1.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€í•˜ë ¤ëŠ” ëª¨ë¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "model_paths = [\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train2/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train3/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train4/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train5/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train6/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train7/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train8/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train9/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/axial_10/cross_data/kfold_demo/train10/weights/best.pt\"\n",
    "]\n",
    "\n",
    "experiment_name = 'test'\n",
    "work_name = 'cross'\n",
    "train_dir = os.path.join('runs', experiment_name)\n",
    "\n",
    "# ê¸°ì¡´ ê²°ê³¼ í´ë” ì‚­ì œ\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "\n",
    "# ë©”íŠ¸ë¦­ ê°’ì„ ì €ìž¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "metric_values = dict()\n",
    "\n",
    "# ê° ëª¨ë¸ì— ëŒ€í•´ í‰ê°€ ìˆ˜í–‰\n",
    "for model_path in model_paths:\n",
    "    train_model = YOLO(model_path)\n",
    "    results = train_model.val(name=os.path.join(experiment_name, f'{experiment_name}_{work_name}'), split=\"test\")\n",
    "    \n",
    "    # ê²°ê³¼ ë©”íŠ¸ë¦­ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ìž¥\n",
    "    for metric, metric_val in results.results_dict.items():\n",
    "        if metric not in metric_values:\n",
    "            metric_values[metric] = []\n",
    "        metric_values[metric].append(metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
      "mean              0.857034           0.826695          0.889357   \n",
      "std               0.054650           0.025856          0.019220   \n",
      "min               0.754917           0.765432          0.854504   \n",
      "max               0.911056           0.851852          0.911451   \n",
      "\n",
      "      metrics/mAP50-95(B)   fitness  \n",
      "mean             0.660521  0.683404  \n",
      "std              0.015189  0.015273  \n",
      "min              0.634193  0.656707  \n",
      "max              0.688217  0.709203  \n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°í”„ë ˆìž„ ìƒì„±\n",
    "metric_df = pd.DataFrame.from_dict(metric_values)\n",
    "\n",
    "# ì›í•˜ëŠ” ë©”íŠ¸ë¦­ë“¤ì˜ í†µê³„ëŸ‰ ì¶œë ¥\n",
    "visualize_metric = ['mean', 'std', 'min', 'max']\n",
    "metric_summary = metric_df.describe().loc[visualize_metric]\n",
    "\n",
    "print(metric_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
