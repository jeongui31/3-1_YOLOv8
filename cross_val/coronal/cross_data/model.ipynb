{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal/yolo_data/labels/test... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<00:00, 679.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/under1/Detect/jeongui/cross_val/coronal/yolo_data/labels/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.529      0.785      0.572      0.428\n",
      "              negative         32         34       0.42      0.937      0.519      0.407\n",
      "              positive         46         49      0.639      0.633      0.624       0.45\n",
      "Speed: 3.8ms preprocess, 4.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.554      0.784      0.634      0.462\n",
      "              negative         32         34      0.459      0.853      0.613      0.468\n",
      "              positive         46         49      0.649      0.714      0.655      0.456\n",
      "Speed: 3.6ms preprocess, 2.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross2\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.593      0.698      0.668      0.505\n",
      "              negative         32         34      0.498      0.676      0.653      0.514\n",
      "              positive         46         49      0.688      0.719      0.684      0.496\n",
      "Speed: 3.5ms preprocess, 1.7ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross3\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.584      0.787      0.722      0.543\n",
      "              negative         32         34      0.496      0.824      0.683      0.543\n",
      "              positive         46         49      0.671      0.751      0.761      0.544\n",
      "Speed: 4.0ms preprocess, 1.9ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross4\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/coronal/yolo_data/labels/test.cache... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         78         83      0.539      0.686      0.587       0.43\n",
      "              negative         32         34      0.446      0.759      0.548      0.432\n",
      "              positive         46         49      0.632      0.612      0.627      0.428\n",
      "Speed: 3.6ms preprocess, 13.0ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€í•˜ë ¤ëŠ” ëª¨ë¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "model_paths = [\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal/cross_data/kfold_demo/train/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal/cross_data/kfold_demo/train2/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal/cross_data/kfold_demo/train3/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal/cross_data/kfold_demo/train4/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/coronal/cross_data/kfold_demo/train5/weights/best.pt\"\n",
    "]\n",
    "\n",
    "experiment_name = 'test'\n",
    "work_name = 'cross'\n",
    "train_dir = os.path.join('runs', experiment_name)\n",
    "\n",
    "# ê¸°ì¡´ ê²°ê³¼ í´ë” ì‚­ì œ\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "\n",
    "# ë©”íŠ¸ë¦­ ê°’ì„ ì €ìž¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "metric_values = dict()\n",
    "\n",
    "# ê° ëª¨ë¸ì— ëŒ€í•´ í‰ê°€ ìˆ˜í–‰\n",
    "for model_path in model_paths:\n",
    "    train_model = YOLO(model_path)\n",
    "    results = train_model.val(name=os.path.join(experiment_name, f'{experiment_name}_{work_name}'), split=\"test\")\n",
    "    \n",
    "    # ê²°ê³¼ ë©”íŠ¸ë¦­ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ìž¥\n",
    "    for metric, metric_val in results.results_dict.items():\n",
    "        if metric not in metric_values:\n",
    "            metric_values[metric] = []\n",
    "        metric_values[metric].append(metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
      "mean              0.559835           0.747805          0.636620   \n",
      "std               0.027697           0.051325          0.061060   \n",
      "min               0.529383           0.685653          0.571761   \n",
      "max               0.593127           0.787023          0.721799   \n",
      "\n",
      "      metrics/mAP50-95(B)   fitness  \n",
      "mean             0.473741  0.490029  \n",
      "std              0.049871  0.050938  \n",
      "min              0.428472  0.442801  \n",
      "max              0.543428  0.561265  \n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°í”„ë ˆìž„ ìƒì„±\n",
    "metric_df = pd.DataFrame.from_dict(metric_values)\n",
    "\n",
    "# ì›í•˜ëŠ” ë©”íŠ¸ë¦­ë“¤ì˜ í†µê³„ëŸ‰ ì¶œë ¥\n",
    "visualize_metric = ['mean', 'std', 'min', 'max']\n",
    "metric_summary = metric_df.describe().loc[visualize_metric]\n",
    "\n",
    "print(metric_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
