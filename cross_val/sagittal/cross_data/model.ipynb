{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/sagittal/yolo_data/labels/test... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<00:00, 709.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/under1/Detect/jeongui/cross_val/sagittal/yolo_data/labels/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         70         77      0.405      0.655      0.478      0.347\n",
      "              negative         35         39      0.422      0.337      0.355       0.24\n",
      "              positive         35         38      0.388      0.974      0.602      0.455\n",
      "Speed: 3.1ms preprocess, 4.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/sagittal/yolo_data/labels/test.cache... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         70         77      0.416      0.692      0.463      0.331\n",
      "              negative         35         39      0.403      0.694      0.447        0.3\n",
      "              positive         35         38      0.428       0.69       0.48      0.362\n",
      "Speed: 4.1ms preprocess, 2.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross2\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/sagittal/yolo_data/labels/test.cache... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         70         77       0.43      0.691      0.486      0.359\n",
      "              negative         35         39      0.459      0.435      0.476      0.325\n",
      "              positive         35         38      0.401      0.947      0.496      0.393\n",
      "Speed: 3.2ms preprocess, 1.6ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross3\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/sagittal/yolo_data/labels/test.cache... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         70         77      0.447      0.599      0.473      0.342\n",
      "              negative         35         39      0.503      0.462      0.463       0.32\n",
      "              positive         35         38      0.391      0.737      0.483      0.363\n",
      "Speed: 2.8ms preprocess, 1.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross4\u001b[0m\n",
      "Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.14 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/under1/Detect/jeongui/cross_val/sagittal/yolo_data/labels/test.cache... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         70         77      0.399      0.742      0.462      0.333\n",
      "              negative         35         39      0.446       0.59      0.461      0.322\n",
      "              positive         35         38      0.352      0.895      0.464      0.343\n",
      "Speed: 3.0ms preprocess, 1.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test/test_cross5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€í•˜ë ¤ëŠ” ëª¨ë¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "model_paths = [\n",
    "    \"/home/under1/Detect/jeongui/cross_val/sagittal/cross_data/kfold_demo/train/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/sagittal/cross_data/kfold_demo/train2/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/sagittal/cross_data/kfold_demo/train3/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/sagittal/cross_data/kfold_demo/train4/weights/best.pt\",\n",
    "    \"/home/under1/Detect/jeongui/cross_val/sagittal/cross_data/kfold_demo/train5/weights/best.pt\"\n",
    "]\n",
    "\n",
    "experiment_name = 'test'\n",
    "work_name = 'cross'\n",
    "train_dir = os.path.join('runs', experiment_name)\n",
    "\n",
    "# ê¸°ì¡´ ê²°ê³¼ í´ë” ì‚­ì œ\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "\n",
    "# ë©”íŠ¸ë¦­ ê°’ì„ ì €ìž¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "metric_values = dict()\n",
    "\n",
    "# ê° ëª¨ë¸ì— ëŒ€í•´ í‰ê°€ ìˆ˜í–‰\n",
    "for model_path in model_paths:\n",
    "    train_model = YOLO(model_path)\n",
    "    results = train_model.val(name=os.path.join(experiment_name, f'{experiment_name}_{work_name}'), split=\"test\")\n",
    "    \n",
    "    # ê²°ê³¼ ë©”íŠ¸ë¦­ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ìž¥\n",
    "    for metric, metric_val in results.results_dict.items():\n",
    "        if metric not in metric_values:\n",
    "            metric_values[metric] = []\n",
    "        metric_values[metric].append(metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
      "mean              0.419276           0.675919          0.472574   \n",
      "std               0.019479           0.052909          0.010019   \n",
      "min               0.398633           0.599190          0.462302   \n",
      "max               0.446911           0.742240          0.486059   \n",
      "\n",
      "      metrics/mAP50-95(B)   fitness  \n",
      "mean             0.342428  0.355443  \n",
      "std              0.011400  0.011253  \n",
      "min              0.331203  0.344431  \n",
      "max              0.359054  0.371754  \n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°í”„ë ˆìž„ ìƒì„±\n",
    "metric_df = pd.DataFrame.from_dict(metric_values)\n",
    "\n",
    "# ì›í•˜ëŠ” ë©”íŠ¸ë¦­ë“¤ì˜ í†µê³„ëŸ‰ ì¶œë ¥\n",
    "visualize_metric = ['mean', 'std', 'min', 'max']\n",
    "metric_summary = metric_df.describe().loc[visualize_metric]\n",
    "\n",
    "print(metric_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
